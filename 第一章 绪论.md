# 第一章 绪论

深度学习是机器学习的一个分支，是指一类问题以及解决这类问题的方法：
1. 从一组有限样本出发。
2. 通过算法总结出一般性规律。
3. 应用到新的未知样本（预测）。

深度学习采用的模型比较复杂，从样本的原始输入到输出目标之间会经过多个线性或非线性组件（神经网络层、激活函数等），每个组件都会对数据进行加工处理，最后我们其实并不知道每个组件的贡献度，这个问题叫做**贡献度分配问题**。

目前，一种可以比较好解决贡献度分配问题的模型是**人工神经网络（Artificial Neural Network，ANN）**。人工神经网络，也简称神经网络，是一种受人脑神经系统的工作方式启发而构造的数学模型。

神经网络与深度学习并不等价，神经网络是用于解决深度学习的一种主要模型。

## 1.1 人工智能

**人工智能（Artificial Intelligence）** 就是让机器具有人的智能。

著名的**图灵测试**。

John McCarthy提出了人工智能的定义：人工智能就是要让机器的行为看起来就像是人所表现出的智能行为一样。

人工智能的主要领域：
1. 感知：模拟人的感知能力，对外部刺激信息（视觉和语音等）进行感知和加工。主要研究领域包括语音信息处理和计算机视觉等。
2. 学习：模拟人的学习能力，主要研究如何从样例或从与环境的交互中进行学习．主要研究领域包括监督学习、无监督学习和强化学习等。
3. 认知：模拟人的认知能力，主要研究领域包括知识表示、自然语言理解、推理、规划、决策等。

### 1.1.1 人工智能的发展历史

简要来讲就是经过好几次低谷期和高潮。

### 1.1.2 人工智能的流派

符号主义、连接主义、行为主义。

## 1.2 机器学习

机器学习关注如何学习一个预测模型，首先从数据中提取特征，输入这些特征学习出一个预测模型，再用这个预测模型对新数据进行预测。机器学习一般包含：
1. 数据预处理：对原始数据做数据清理和加工
2. 特征提取：提取高质量特征
3. 特征转换：对特征加工，如升维或降维
4. 预测：学习函数并预测

前三步称为特征处理，一般需要人工干预，利用人类经验来选取好的特征。

## 1.3 表示学习

为提高机器学习系统的准确率，我们需要将输入信息转化为有效的特征，或者更一般性地称为**表示（Representation）**。如果一种算法可以自动学习出有效特征，并提高机器学习模型的性能，那么这种学习就可以被称为**表示学习（Representation Learning）**。

表示学习的关键是解决**语义鸿沟**，即输入数据的底层特征和高层语义信息之间的不一致性和差异性。比如输入数据的底层特征存在差异，但从高层语义信息来看表示的是同一类事物。表示学习中有两个核心问题：
1. 什么是一个好的表示？
2. 如何学习到好的表示？

### 1.3.1 局部表示和分布式表示

一个好的表示一般有以下几个优点：
1. 一个好的表示应该具有很强的表示能力，即同样大小的向量可以表示更多信息。
2. 一个好的表示应该使后续的学习任务变得简单，即需要包含更高层的语义信息。
3. 一个好的表示应该具有一般性，是任务或领域独立的。虽然目前的大部分表示学习方法还是基于某个任务来学习，但我们期望其学到的表示可以比较容易地迁移到其他任务上。

机器学习中有两种方式表示特征：**局部表示（Local Representation）** 和 **分布式表示（Distributed Reprensentation）**。

局部表示和分布式表示的区别在于离散和连续，比如对于颜色的表示，除了基本的“红”、“蓝”、“白”等，还有“中国蓝”、“咖啡色”等。如果是局部表示，我们可以用one-hot向量的形式表示，将所有颜色的名字构成一个词表，one-hot向量的第i个元素有0和1两种取值，取值为1代表含有这种颜色，反之没有；而分布式表示可以用RGB值来表示，实际上就是把一些基本颜色归一化到[0, 1]区间上。

局部表示：
1. 优点
- 解释性好，有利于人工归纳和总结特征。
- 表示向量通常是稀疏的二值向量，用于线性模型时计算效率很高。
2. 缺点
- 表示向量维数较高，不能拓展，有新的元素需要增加一维。
- 难以观察不同取值的特征的相似性。

分布式表示：
表示能力强，同时表示向量维低，可拓展性强，同时易于比较不同取值的特征的相似性。

我们可以用神经网络来将高维的局部表示空间映射到低维的分布式表示空间，在机器学习中，这个过程称为**嵌入**。

### 1.3.2 表示学习

要学习到一种好的高层语义表示（一般为分布式表示），通常需要从底层特征开始，经过多步非线性转换才能得到。深层结构的优点是可以增加特征的重用性，从而指数级地增加表示能力．因此，表示学习的关键是构建具有一定深度的多层次特征表示。

## 1.4 深度学习

**深度学习（Deep Learning，DL）** 即为从数据中学习一个“深度模型”，和“浅层学习”不同，深度学习需要解决的关键问题时**贡献度分配问题（Credit Assignment Problem，CAP）**，即一个系统中不同组件或其参数对最终系统输出结果的贡献或影响。深度学习可以看作一种**强化学习（Reinforcement Learning，RL）**，每个内部组件并不能直接得到监督信息，需要通过整个模型的最终监督信息（奖励）
得到，并且有一定的延时性。

目前深度学习采用的模型主要是神经网络模型，其主要原因是神经网络模型可以使用误差反向传播算法，从而可以比较好地解决贡献度分配问题。

**端对端学习（End-to-End Learning)**，只在学习过程中不进行分模块或分阶段训练，直接优化任务的总体目标，训练数据为“输入-输出”对的形式。

## 1.5 神经网络

### 1.5.1 人脑神经网络

神经元结构之类的。

### 1.5.2 人工神经网络

不同层节点之间的连接赋予不同权重，当前网络层的数据经过权重和偏置的线性变换处理后传入到激活函数中，再传入下一网络层。

### 1.5.3 神经网络的发展历史

有点无聊，看书吧。

